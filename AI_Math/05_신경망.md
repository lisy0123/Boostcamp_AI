# 신경망

- **신경망(neural network)**

  - 비선형모델

  - 각 데이터에 대해 d개의 변수로 p개의 선형모델을 만들어 p개의 잠재변수를 설명하는 모델

    <img src="https://user-images.githubusercontent.com/60209937/128128062-064f07ec-77e6-4ccf-8e84-89af27d4b16e.png" alt="1" style="zoom:80%;" />

    <img src="https://user-images.githubusercontent.com/60209937/128128066-51f5ba19-3cee-4cf7-9854-9b085cfc1f18.png" alt="2" style="zoom:90%;" />

- 소프트맥스

- 모든 출력물 고려

- 신경망: 선형모델과 활성함수(activation function)를 합성한 함수

- 해당 주소의 출력값만 고려

- 잠재벡터(히든벡터)

- **활성함수**

  - 비선형(nonlinear) 함수, 딥러닝에서 중요한 개념
  - 활성함수를 쓰지 않으면 딥러닝은 선형모형과 차이 X
  - 시그모이드(sigmod) 함수나 tanh 함수 => 전통적으로 많이 쓰던 활성함수
  - ReLU 함수 => 딥러닝에서 많이 씀

- 2층(2-layers) 신경망

- 다층(multi-layer) 퍼셉트론(MLP): 신경망이 여러층 합성된 함수

- 순전파

- 층이 깊을수록 목적함수를 근사하는데 필요한 뉴런(노드)의 숫자가 훨씬 빨리 줄어들어 좀 더 효율적으로 학습 가능

  ㅇ

- 역전파(backpropagation) 알고리즘

  각 층 파라미터의 그레디언트 벡터는 윗층부터 역순으로 계산

- 역전파 알고리즘은 합성함수 미분법인 연쇄법칙(chain-rule) 기반 자동미분(auto-differentiation) 사용

- 